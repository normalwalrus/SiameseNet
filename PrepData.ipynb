{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from glob import glob\n",
    "from random import choice\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a dictionary with (Family) \\\\\\\\ (ID) as the key and the path to the images under that one person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./train\\\\F0002\\\\MID1\\\\P00009_face3.jpg',\n",
       " './train\\\\F0002\\\\MID1\\\\P00010_face4.jpg',\n",
       " './train\\\\F0002\\\\MID1\\\\P00011_face1.jpg',\n",
       " './train\\\\F0002\\\\MID1\\\\P00012_face2.jpg',\n",
       " './train\\\\F0002\\\\MID1\\\\P00013_face2.jpg',\n",
       " './train\\\\F0002\\\\MID1\\\\P00014_face2.jpg',\n",
       " './train\\\\F0002\\\\MID1\\\\P00015_face2.jpg',\n",
       " './train\\\\F0002\\\\MID1\\\\P00016_face2.jpg',\n",
       " './train\\\\F0002\\\\MID1\\\\P00017_face3.jpg',\n",
       " './train\\\\F0002\\\\MID1\\\\P00018_face1.jpg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_file_path = \"./train_relationships.csv\"\n",
    "train_images_path = \"./train/\"\n",
    "\n",
    "all_images = glob(train_images_path + \"*/*/*.jpg\")\n",
    "train_person_to_images = {}\n",
    "\n",
    "for x in all_images:\n",
    "\n",
    "    if x.split(\"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2] not in train_person_to_images:\n",
    "        train_person_to_images[x.split(\"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2]] = [x]\n",
    "\n",
    "    else:\n",
    "        train_person_to_images[x.split(\"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2]].append(x)\n",
    "\n",
    "train_people = [x.split(\"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2] for x in all_images]\n",
    "train_people = list(dict.fromkeys(train_people)) # removing the duplicates\n",
    "\n",
    "relationships = pd.read_csv(train_file_path)\n",
    "relationships = list(zip(relationships.p1.values, relationships.p2.values))\n",
    "relationships = [x for x in relationships if x[0] in train_people and x[1] in train_people] #Check if people are in the training dataset\n",
    "\n",
    "train_person_to_images[relationships[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
