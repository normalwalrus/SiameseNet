{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset class for getting positive and negative classes for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a dictionary with (Family) \\\\\\\\ (ID) as the key and the path to the images under that one person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Utils.DatasetClass import SmileDataset\n",
    "import os\n",
    "import random\n",
    "\n",
    "train_file_path = \"./train_relationships.csv\"\n",
    "train_images_path = \"./data/norm-sharp-greyscale/train/\"\n",
    "\n",
    "all_images = glob(train_images_path + \"*/*/*.jpg\")\n",
    "train_person_to_images = {}\n",
    "val_person_to_images = {}\n",
    "\n",
    "# Getting 0.1 of the total training as validation\n",
    "percentage_val = 0.1\n",
    "train_names = [folder for folder in os.listdir(train_images_path) if  os.path.isdir(os.path.join(train_images_path, folder))]\n",
    "val_families = random.sample(train_names, int(percentage_val * len(train_names)))\n",
    "\n",
    "train_images = []\n",
    "val_images = []\n",
    "\n",
    "for x in all_images:\n",
    "\n",
    "    if x.split(\"\\\\\")[-3] not in val_families:\n",
    "\n",
    "        if x.split(\"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2] not in train_person_to_images:\n",
    "            train_person_to_images[x.split(\"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2]] = [x]\n",
    "\n",
    "        else:\n",
    "            train_person_to_images[x.split(\"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2]].append(x)\n",
    "\n",
    "        train_images.append(x)\n",
    "    \n",
    "    else:\n",
    "        if x.split(\"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2] not in val_person_to_images:\n",
    "            val_person_to_images[x.split(\"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2]] = [x]\n",
    "\n",
    "        else:\n",
    "            val_person_to_images[x.split(\"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2]].append(x)\n",
    "\n",
    "        val_images.append(x)\n",
    "\n",
    "train_people = [x.split(\"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2] for x in train_images]\n",
    "train_people = list(dict.fromkeys(train_people)) # removing the duplicates\n",
    "\n",
    "val_people = [x.split(\"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2] for x in val_images]\n",
    "val_people = list(dict.fromkeys(val_people)) # removing the duplicates\n",
    "\n",
    "relationships = pd.read_csv(train_file_path)\n",
    "relationships = list(zip(relationships.p1.values, relationships.p2.values))\n",
    "\n",
    "train_relationships = [x for x in relationships if x[0] in train_people and x[1] in train_people] #Check if people are in the training dataset\n",
    "val_relationships = [x for x in relationships if x[0] in val_people and x[1] in val_people]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the SmileDataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = SmileDataset(relations = train_relationships, person_to_image= train_person_to_images)\n",
    "trainloader = DataLoader(train_dataset, batch_size= 100, shuffle = True)\n",
    "\n",
    "val_dataset = SmileDataset(relations = val_relationships, person_to_image= val_person_to_images)\n",
    "valloader = DataLoader(val_dataset, batch_size= 100, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training time!! :) (Work in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, valloader, val_dataset, device, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    for batch in valloader:\n",
    "        tensor1, tensor2, label = batch\n",
    "        tensor1, tensor2, label = tensor1.to(device), tensor2.to(device), label.float().view(-1,1).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(tensor1, tensor2)\n",
    "            preds = output>0.5\n",
    "            loss = criterion(output, label)\n",
    "            \n",
    "        val_loss += loss.item()\n",
    "        running_corrects += torch.sum(preds == (label>0.5))\n",
    "    \n",
    "    val_loss /= len(val_dataset)\n",
    "    val_acc = running_corrects.item()/len(val_dataset)\n",
    "\n",
    "    return val_loss, val_acc\n",
    "\n",
    "def train(model, trainloader, train_dataset, optimizer, device, criterion):\n",
    "    train_loss = 0.0\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for batch in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        tensor1, tensor2, label = batch\n",
    "        tensor1, tensor2, label = tensor1.to(device), tensor2.to(device), label.float().view(-1,1).to(device)\n",
    "        output = model(tensor1, tensor2)\n",
    "\n",
    "        preds = output>0.5\n",
    "        \n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        running_loss += loss.item()\n",
    "        running_corrects += torch.sum(preds == label)\n",
    "\n",
    "    train_loss /= len(train_dataset)\n",
    "    train_acc = running_corrects.item()/len(train_dataset)\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ianch\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1], \tval loss: 0.006713\tacc: 0.68768\n",
      "[1], \ttrain loss: 0.0059943\tacc: 0.65158\n",
      "[2], \tval loss: 0.0063095\tacc: 0.69328\n",
      "[2], \ttrain loss: 0.0056323\tacc: 0.68702\n",
      "[3], \tval loss: 0.0060564\tacc: 0.67367\n",
      "[3], \ttrain loss: 0.0054479\tacc: 0.7015\n",
      "[4], \tval loss: 0.0059456\tacc: 0.72829\n",
      "[4], \ttrain loss: 0.0053735\tacc: 0.71414\n",
      "[5], \tval loss: 0.0065966\tacc: 0.65546\n",
      "[5], \ttrain loss: 0.0052969\tacc: 0.71764\n",
      "[6], \tval loss: 0.0059442\tacc: 0.72689\n",
      "[6], \ttrain loss: 0.0052488\tacc: 0.71547\n",
      "[7], \tval loss: 0.0062991\tacc: 0.72129\n",
      "[7], \ttrain loss: 0.0049671\tacc: 0.74326\n",
      "[8], \tval loss: 0.0066192\tacc: 0.69328\n",
      "[8], \ttrain loss: 0.0050895\tacc: 0.73062\n",
      "[9], \tval loss: 0.0062492\tacc: 0.67647\n",
      "[9], \ttrain loss: 0.0049437\tacc: 0.73943\n",
      "[10], \tval loss: 0.0066834\tacc: 0.64706\n",
      "[10], \ttrain loss: 0.004925\tacc: 0.75092\n",
      "[11], \tval loss: 0.0076739\tacc: 0.61204\n",
      "[11], \ttrain loss: 0.0048673\tacc: 0.7406\n",
      "[12], \tval loss: 0.0062207\tacc: 0.71289\n",
      "[12], \ttrain loss: 0.0046751\tacc: 0.76023\n",
      "[13], \tval loss: 0.007481\tacc: 0.65266\n",
      "[13], \ttrain loss: 0.0047798\tacc: 0.75724\n",
      "[14], \tval loss: 0.0065785\tacc: 0.67367\n",
      "[14], \ttrain loss: 0.0045436\tacc: 0.76938\n",
      "[15], \tval loss: 0.0066976\tacc: 0.66667\n",
      "[15], \ttrain loss: 0.0045317\tacc: 0.77687\n",
      "[16], \tval loss: 0.0071946\tacc: 0.67367\n",
      "[16], \ttrain loss: 0.0044364\tacc: 0.77271\n",
      "[17], \tval loss: 0.0064557\tacc: 0.65126\n",
      "[17], \ttrain loss: 0.0045304\tacc: 0.76922\n",
      "[18], \tval loss: 0.0077594\tacc: 0.62045\n",
      "[18], \ttrain loss: 0.0043562\tacc: 0.77854\n",
      "[19], \tval loss: 0.0067653\tacc: 0.67647\n",
      "[19], \ttrain loss: 0.0041386\tacc: 0.79933\n",
      "[20], \tval loss: 0.0064773\tacc: 0.68627\n",
      "[20], \ttrain loss: 0.0041816\tacc: 0.79601\n",
      "[21], \tval loss: 0.0069637\tacc: 0.68487\n",
      "[21], \ttrain loss: 0.0042125\tacc: 0.79268\n",
      "[22], \tval loss: 0.007108\tacc: 0.66387\n",
      "[22], \ttrain loss: 0.0040484\tacc: 0.803\n",
      "[23], \tval loss: 0.0072745\tacc: 0.65966\n",
      "[23], \ttrain loss: 0.0039172\tacc: 0.81015\n",
      "[24], \tval loss: 0.0072701\tacc: 0.64006\n",
      "[24], \ttrain loss: 0.0040257\tacc: 0.81431\n",
      "[25], \tval loss: 0.0075221\tacc: 0.66246\n",
      "[25], \ttrain loss: 0.0038926\tacc: 0.81298\n",
      "[26], \tval loss: 0.007765\tacc: 0.62885\n",
      "[26], \ttrain loss: 0.0039439\tacc: 0.81897\n",
      "[27], \tval loss: 0.0080785\tacc: 0.65686\n",
      "[27], \ttrain loss: 0.0038255\tacc: 0.8178\n",
      "[28], \tval loss: 0.0079811\tacc: 0.62605\n",
      "[28], \ttrain loss: 0.0038317\tacc: 0.8173\n",
      "[29], \tval loss: 0.008721\tacc: 0.65966\n",
      "[29], \ttrain loss: 0.0036445\tacc: 0.82928\n",
      "[30], \tval loss: 0.0073011\tacc: 0.65966\n",
      "[30], \ttrain loss: 0.0036687\tacc: 0.82629\n",
      "[31], \tval loss: 0.0081356\tacc: 0.66387\n",
      "[31], \ttrain loss: 0.0037251\tacc: 0.82329\n",
      "[32], \tval loss: 0.0075586\tacc: 0.65126\n",
      "[32], \ttrain loss: 0.0035851\tacc: 0.83727\n",
      "[33], \tval loss: 0.007563\tacc: 0.67927\n",
      "[33], \ttrain loss: 0.0034268\tacc: 0.84226\n",
      "[34], \tval loss: 0.008016\tacc: 0.66106\n",
      "[34], \ttrain loss: 0.003439\tacc: 0.84459\n",
      "[35], \tval loss: 0.0081212\tacc: 0.68908\n",
      "[35], \ttrain loss: 0.0034443\tacc: 0.84526\n",
      "[36], \tval loss: 0.010438\tacc: 0.62045\n",
      "[36], \ttrain loss: 0.00334\tacc: 0.84825\n",
      "[37], \tval loss: 0.0080188\tacc: 0.63866\n",
      "[37], \ttrain loss: 0.0033707\tacc: 0.85125\n",
      "[38], \tval loss: 0.0076441\tacc: 0.66387\n",
      "[38], \ttrain loss: 0.0034288\tacc: 0.8371\n",
      "[39], \tval loss: 0.0077884\tacc: 0.68487\n",
      "[39], \ttrain loss: 0.0032872\tacc: 0.85358\n",
      "[40], \tval loss: 0.008211\tacc: 0.65686\n",
      "[40], \ttrain loss: 0.0033392\tacc: 0.84676\n",
      "[41], \tval loss: 0.0086795\tacc: 0.63165\n",
      "[41], \ttrain loss: 0.0033176\tacc: 0.85324\n",
      "[42], \tval loss: 0.0096872\tacc: 0.63305\n",
      "[42], \ttrain loss: 0.0031732\tacc: 0.85707\n",
      "[43], \tval loss: 0.0092593\tacc: 0.64286\n",
      "[43], \ttrain loss: 0.0032586\tacc: 0.85474\n",
      "[44], \tval loss: 0.0082866\tacc: 0.66106\n",
      "[44], \ttrain loss: 0.0032412\tacc: 0.86206\n",
      "[45], \tval loss: 0.0098296\tacc: 0.61765\n",
      "[45], \ttrain loss: 0.0031787\tacc: 0.85607\n",
      "[46], \tval loss: 0.0087091\tacc: 0.63025\n",
      "[46], \ttrain loss: 0.0030735\tacc: 0.86123\n",
      "[47], \tval loss: 0.0085415\tacc: 0.64706\n",
      "[47], \ttrain loss: 0.0030228\tacc: 0.86572\n",
      "[48], \tval loss: 0.0079724\tacc: 0.64986\n",
      "[48], \ttrain loss: 0.0031807\tacc: 0.85458\n",
      "[49], \tval loss: 0.0093638\tacc: 0.65406\n",
      "[49], \ttrain loss: 0.0030266\tacc: 0.86606\n",
      "[50], \tval loss: 0.009906\tacc: 0.60644\n",
      "[50], \ttrain loss: 0.0030272\tacc: 0.86872\n"
     ]
    }
   ],
   "source": [
    "from Utils.SiameseNet import SiameseNet, SiameseNet_large, MultiEncoding_SiameseNet, MultiEncoding_SiameseNet_Large\n",
    "import os\n",
    "\n",
    "name  = 'MultiEncoding_SiameseNet_large_norm_sharpen_greyscale'\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = MultiEncoding_SiameseNet_Large().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(params= model.parameters(), lr = lr)\n",
    "\n",
    "num_epoch = 50\n",
    "best_epoch = 0\n",
    "best_val_acc = 0\n",
    "\n",
    "history = []\n",
    "accuracy = []\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    \n",
    "    train_loss, train_acc = train(model, trainloader, train_dataset, optimizer, device, criterion)\n",
    "    val_loss, val_acc  = validate(model, valloader, val_dataset, device, criterion)\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_epoch = epoch\n",
    "\n",
    "        save_path = os.getcwd() +'\\\\models\\\\{}_best.pt'.format(name)\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "\n",
    "\n",
    "    print('[{}], \\tval loss: {:.5}\\tacc: {:.5}'.format(epoch+1, val_loss, val_acc))\n",
    "    print('[{}], \\ttrain loss: {:.5}\\tacc: {:.5}'.format(epoch+1, train_loss, train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch : 4\n"
     ]
    }
   ],
   "source": [
    "print('best epoch : {}'.format(best_epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.getcwd() +'\\\\models\\\\{}_epoch{}.pt'.format(name, epoch+1)\n",
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
