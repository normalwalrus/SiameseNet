{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset class for getting positive and negative classes for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a dictionary with (Family) \\\\\\\\ (ID) as the key and the path to the images under that one person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Utils.DatasetClass import SmileDataset\n",
    "import os\n",
    "import random\n",
    "\n",
    "train_file_path = \"./train_relationships.csv\"\n",
    "train_images_path = \"./train/\"\n",
    "\n",
    "all_images = glob(train_images_path + \"*/*/*.jpg\")\n",
    "train_person_to_images = {}\n",
    "val_person_to_images = {}\n",
    "\n",
    "# Getting 0.1 of the total training as validation\n",
    "percentage_val = 0.1\n",
    "train_names = [folder for folder in os.listdir(train_images_path) if  os.path.isdir(os.path.join(train_images_path, folder))]\n",
    "val_families = random.sample(train_names, int(percentage_val * len(train_names)))\n",
    "\n",
    "train_images = []\n",
    "val_images = []\n",
    "\n",
    "for x in all_images:\n",
    "\n",
    "    if x.split(\"\\\\\")[-3] not in val_families:\n",
    "\n",
    "        if x.split(\"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2] not in train_person_to_images:\n",
    "            train_person_to_images[x.split(\"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2]] = [x]\n",
    "\n",
    "        else:\n",
    "            train_person_to_images[x.split(\"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2]].append(x)\n",
    "\n",
    "        train_images.append(x)\n",
    "    \n",
    "    else:\n",
    "        if x.split(\"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2] not in val_person_to_images:\n",
    "            val_person_to_images[x.split(\"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2]] = [x]\n",
    "\n",
    "        else:\n",
    "            val_person_to_images[x.split(\"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2]].append(x)\n",
    "\n",
    "        val_images.append(x)\n",
    "\n",
    "train_people = [x.split(\"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2] for x in train_images]\n",
    "train_people = list(dict.fromkeys(train_people)) # removing the duplicates\n",
    "\n",
    "val_people = [x.split(\"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2] for x in val_images]\n",
    "val_people = list(dict.fromkeys(val_people)) # removing the duplicates\n",
    "\n",
    "relationships = pd.read_csv(train_file_path)\n",
    "relationships = list(zip(relationships.p1.values, relationships.p2.values))\n",
    "\n",
    "train_relationships = [x for x in relationships if x[0] in train_people and x[1] in train_people] #Check if people are in the training dataset\n",
    "val_relationships = [x for x in relationships if x[0] in val_people and x[1] in val_people]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the SmileDataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = SmileDataset(relations = train_relationships, person_to_image= train_person_to_images)\n",
    "trainloader = DataLoader(train_dataset, batch_size= 100, shuffle = True)\n",
    "\n",
    "val_dataset = SmileDataset(relations = val_relationships, person_to_image= val_person_to_images)\n",
    "valloader = DataLoader(val_dataset, batch_size= 100, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training time!! :) (Work in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, valloader, val_dataset, device, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    for batch in valloader:\n",
    "        tensor1, tensor2, label = batch\n",
    "        tensor1, tensor2, label = tensor1.to(device), tensor2.to(device), label.float().view(-1,1).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(tensor1, tensor2)\n",
    "            preds = output>0.5\n",
    "            loss = criterion(output, label)\n",
    "            \n",
    "        val_loss += loss.item()\n",
    "        running_corrects += torch.sum(preds == (label>0.5))\n",
    "    \n",
    "    val_loss /= len(val_dataset)\n",
    "    val_acc = running_corrects.item()/len(val_dataset)\n",
    "\n",
    "    return val_loss, val_acc\n",
    "\n",
    "def train(model, trainloader, train_dataset, optimizer, device, criterion):\n",
    "    train_loss = 0.0\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for batch in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        tensor1, tensor2, label = batch\n",
    "        tensor1, tensor2, label = tensor1.to(device), tensor2.to(device), label.float().view(-1,1).to(device)\n",
    "        output = model(tensor1, tensor2)\n",
    "\n",
    "        preds = output>0.5\n",
    "        \n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        running_loss += loss.item()\n",
    "        running_corrects += torch.sum(preds == label)\n",
    "\n",
    "    train_loss /= len(train_dataset)\n",
    "    train_acc = running_corrects.item()/len(train_dataset)\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1], \tval loss: 0.0066486\tacc: 0.6653\n",
      "[1], \ttrain loss: 0.0058163\tacc: 0.66939\n",
      "[2], \tval loss: 0.00643\tacc: 0.65164\n",
      "[2], \ttrain loss: 0.0054019\tacc: 0.70244\n",
      "[3], \tval loss: 0.0061044\tacc: 0.68989\n",
      "[3], \ttrain loss: 0.005218\tacc: 0.71061\n",
      "[4], \tval loss: 0.0060328\tacc: 0.70902\n",
      "[4], \ttrain loss: 0.0051097\tacc: 0.72613\n",
      "[5], \tval loss: 0.0065308\tacc: 0.66393\n",
      "[5], \ttrain loss: 0.0050355\tacc: 0.73081\n",
      "[6], \tval loss: 0.0066831\tacc: 0.63661\n",
      "[6], \ttrain loss: 0.0048584\tacc: 0.73982\n",
      "[7], \tval loss: 0.0061191\tacc: 0.64617\n",
      "[7], \ttrain loss: 0.0048953\tacc: 0.74316\n",
      "[8], \tval loss: 0.0069172\tacc: 0.6776\n",
      "[8], \ttrain loss: 0.0047343\tacc: 0.75334\n",
      "[9], \tval loss: 0.0068181\tacc: 0.62295\n",
      "[9], \ttrain loss: 0.0047194\tacc: 0.75517\n",
      "[10], \tval loss: 0.0069646\tacc: 0.6571\n",
      "[10], \ttrain loss: 0.0045373\tacc: 0.76552\n",
      "[11], \tval loss: 0.0070143\tacc: 0.66257\n",
      "[11], \ttrain loss: 0.0045079\tacc: 0.77303\n",
      "[12], \tval loss: 0.0066945\tacc: 0.65164\n",
      "[12], \ttrain loss: 0.0042551\tacc: 0.78555\n",
      "[13], \tval loss: 0.0071505\tacc: 0.65984\n",
      "[13], \ttrain loss: 0.0043049\tacc: 0.78221\n",
      "[14], \tval loss: 0.0069123\tacc: 0.65027\n",
      "[14], \ttrain loss: 0.0042537\tacc: 0.78605\n",
      "[15], \tval loss: 0.0070977\tacc: 0.66393\n",
      "[15], \ttrain loss: 0.0040515\tacc: 0.7999\n",
      "[16], \tval loss: 0.0069627\tacc: 0.64754\n",
      "[16], \ttrain loss: 0.0040853\tacc: 0.79623\n",
      "[17], \tval loss: 0.0071015\tacc: 0.6776\n",
      "[17], \ttrain loss: 0.0040353\tacc: 0.7994\n",
      "[18], \tval loss: 0.0066684\tacc: 0.6653\n",
      "[18], \ttrain loss: 0.0040459\tacc: 0.80557\n",
      "[19], \tval loss: 0.0086099\tacc: 0.64891\n",
      "[19], \ttrain loss: 0.0038156\tacc: 0.81742\n",
      "[20], \tval loss: 0.0076034\tacc: 0.65437\n",
      "[20], \ttrain loss: 0.0039096\tacc: 0.81742\n",
      "[21], \tval loss: 0.0081038\tacc: 0.65574\n",
      "[21], \ttrain loss: 0.0038134\tacc: 0.81292\n",
      "[22], \tval loss: 0.0078258\tacc: 0.6694\n",
      "[22], \ttrain loss: 0.0037227\tacc: 0.8276\n",
      "[23], \tval loss: 0.0073847\tacc: 0.64208\n",
      "[23], \ttrain loss: 0.003702\tacc: 0.8276\n",
      "[24], \tval loss: 0.0087156\tacc: 0.63388\n",
      "[24], \ttrain loss: 0.0034895\tacc: 0.83678\n",
      "[25], \tval loss: 0.0075428\tacc: 0.62705\n",
      "[25], \ttrain loss: 0.0036254\tacc: 0.8271\n",
      "[26], \tval loss: 0.008782\tacc: 0.61885\n",
      "[26], \ttrain loss: 0.003453\tacc: 0.84362\n",
      "[27], \tval loss: 0.0083199\tacc: 0.65027\n",
      "[27], \ttrain loss: 0.0034162\tacc: 0.83812\n",
      "[28], \tval loss: 0.010051\tacc: 0.61339\n",
      "[28], \ttrain loss: 0.0033566\tacc: 0.8503\n",
      "[29], \tval loss: 0.0088877\tacc: 0.61749\n",
      "[29], \ttrain loss: 0.0034039\tacc: 0.83862\n",
      "[30], \tval loss: 0.0093358\tacc: 0.60656\n",
      "[30], \ttrain loss: 0.0032625\tacc: 0.85481\n",
      "[31], \tval loss: 0.0087803\tacc: 0.61749\n",
      "[31], \ttrain loss: 0.0032775\tacc: 0.85564\n",
      "[32], \tval loss: 0.011133\tacc: 0.61066\n",
      "[32], \ttrain loss: 0.0031403\tacc: 0.85497\n",
      "[33], \tval loss: 0.0097005\tacc: 0.61749\n",
      "[33], \ttrain loss: 0.0031967\tacc: 0.8493\n",
      "[34], \tval loss: 0.0092062\tacc: 0.64481\n",
      "[34], \ttrain loss: 0.0030595\tacc: 0.86465\n",
      "[35], \tval loss: 0.009206\tacc: 0.61885\n",
      "[35], \ttrain loss: 0.002998\tacc: 0.87099\n",
      "[36], \tval loss: 0.010172\tacc: 0.59563\n",
      "[36], \ttrain loss: 0.0030597\tacc: 0.86098\n",
      "[37], \tval loss: 0.010164\tacc: 0.63388\n",
      "[37], \ttrain loss: 0.0030408\tacc: 0.85915\n",
      "[38], \tval loss: 0.01044\tacc: 0.61475\n",
      "[38], \ttrain loss: 0.0030013\tacc: 0.87016\n",
      "[39], \tval loss: 0.0088634\tacc: 0.62295\n",
      "[39], \ttrain loss: 0.0029049\tacc: 0.87684\n",
      "[40], \tval loss: 0.010347\tacc: 0.62022\n",
      "[40], \ttrain loss: 0.0029346\tacc: 0.86933\n",
      "[41], \tval loss: 0.0099485\tacc: 0.63115\n",
      "[41], \ttrain loss: 0.0027819\tacc: 0.87917\n",
      "[42], \tval loss: 0.011503\tacc: 0.5806\n",
      "[42], \ttrain loss: 0.002869\tacc: 0.8755\n",
      "[43], \tval loss: 0.010163\tacc: 0.63388\n",
      "[43], \ttrain loss: 0.0027579\tacc: 0.87817\n",
      "[44], \tval loss: 0.0098213\tacc: 0.64344\n",
      "[44], \ttrain loss: 0.0027114\tacc: 0.88618\n",
      "[45], \tval loss: 0.010653\tacc: 0.62022\n",
      "[45], \ttrain loss: 0.0028514\tacc: 0.87717\n",
      "[46], \tval loss: 0.011535\tacc: 0.5929\n",
      "[46], \ttrain loss: 0.0026517\tacc: 0.88251\n",
      "[47], \tval loss: 0.0099379\tacc: 0.64071\n",
      "[47], \ttrain loss: 0.0026855\tacc: 0.88334\n",
      "[48], \tval loss: 0.010902\tacc: 0.60519\n",
      "[48], \ttrain loss: 0.002703\tacc: 0.88067\n",
      "[49], \tval loss: 0.010201\tacc: 0.62842\n",
      "[49], \ttrain loss: 0.0026704\tacc: 0.88117\n",
      "[50], \tval loss: 0.012734\tacc: 0.59016\n",
      "[50], \ttrain loss: 0.0025824\tacc: 0.88368\n",
      "[51], \tval loss: 0.014327\tacc: 0.58607\n",
      "[51], \ttrain loss: 0.0026408\tacc: 0.88818\n",
      "[52], \tval loss: 0.012328\tacc: 0.61066\n",
      "[52], \ttrain loss: 0.0025867\tacc: 0.89019\n",
      "[53], \tval loss: 0.0113\tacc: 0.61202\n",
      "[53], \ttrain loss: 0.0025019\tacc: 0.89236\n",
      "[54], \tval loss: 0.011316\tacc: 0.59563\n",
      "[54], \ttrain loss: 0.0026677\tacc: 0.88385\n",
      "[55], \tval loss: 0.011958\tacc: 0.60792\n",
      "[55], \ttrain loss: 0.0027168\tacc: 0.88084\n",
      "[56], \tval loss: 0.011015\tacc: 0.63251\n",
      "[56], \ttrain loss: 0.002566\tacc: 0.89152\n",
      "[57], \tval loss: 0.011507\tacc: 0.60383\n",
      "[57], \ttrain loss: 0.0023821\tacc: 0.89703\n",
      "[58], \tval loss: 0.012299\tacc: 0.59699\n",
      "[58], \ttrain loss: 0.0025922\tacc: 0.88852\n",
      "[59], \tval loss: 0.014413\tacc: 0.5929\n",
      "[59], \ttrain loss: 0.0023535\tacc: 0.8972\n",
      "[60], \tval loss: 0.011024\tacc: 0.62158\n",
      "[60], \ttrain loss: 0.0024267\tacc: 0.89619\n",
      "[61], \tval loss: 0.0092071\tacc: 0.64481\n",
      "[61], \ttrain loss: 0.0024819\tacc: 0.89636\n",
      "[62], \tval loss: 0.013354\tacc: 0.59973\n",
      "[62], \ttrain loss: 0.0024395\tacc: 0.8982\n",
      "[63], \tval loss: 0.012349\tacc: 0.63115\n",
      "[63], \ttrain loss: 0.0023118\tacc: 0.89803\n",
      "[64], \tval loss: 0.013885\tacc: 0.59016\n",
      "[64], \ttrain loss: 0.0022637\tacc: 0.90554\n",
      "[65], \tval loss: 0.010423\tacc: 0.62978\n",
      "[65], \ttrain loss: 0.0023133\tacc: 0.9017\n",
      "[66], \tval loss: 0.012149\tacc: 0.61475\n",
      "[66], \ttrain loss: 0.002269\tacc: 0.90471\n",
      "[67], \tval loss: 0.012353\tacc: 0.61339\n",
      "[67], \ttrain loss: 0.0022607\tacc: 0.90537\n",
      "[68], \tval loss: 0.013153\tacc: 0.62978\n",
      "[68], \ttrain loss: 0.0023156\tacc: 0.9032\n",
      "[69], \tval loss: 0.01438\tacc: 0.61612\n",
      "[69], \ttrain loss: 0.0023541\tacc: 0.90103\n",
      "[70], \tval loss: 0.012748\tacc: 0.59973\n",
      "[70], \ttrain loss: 0.0022085\tacc: 0.91238\n",
      "[71], \tval loss: 0.011574\tacc: 0.60656\n",
      "[71], \ttrain loss: 0.0021895\tacc: 0.91105\n",
      "[72], \tval loss: 0.010735\tacc: 0.62842\n",
      "[72], \ttrain loss: 0.002108\tacc: 0.91272\n",
      "[73], \tval loss: 0.011541\tacc: 0.64071\n",
      "[73], \ttrain loss: 0.0021783\tacc: 0.91188\n",
      "[74], \tval loss: 0.013006\tacc: 0.60656\n",
      "[74], \ttrain loss: 0.002186\tacc: 0.90921\n",
      "[75], \tval loss: 0.013\tacc: 0.61749\n",
      "[75], \ttrain loss: 0.0022546\tacc: 0.90721\n",
      "[76], \tval loss: 0.013029\tacc: 0.62022\n",
      "[76], \ttrain loss: 0.0022019\tacc: 0.90738\n",
      "[77], \tval loss: 0.013178\tacc: 0.59699\n",
      "[77], \ttrain loss: 0.0021155\tacc: 0.91489\n",
      "[78], \tval loss: 0.01353\tacc: 0.59563\n",
      "[78], \ttrain loss: 0.0021848\tacc: 0.91005\n",
      "[79], \tval loss: 0.016076\tacc: 0.56831\n",
      "[79], \ttrain loss: 0.0021905\tacc: 0.90771\n",
      "[80], \tval loss: 0.013924\tacc: 0.59563\n",
      "[80], \ttrain loss: 0.0020419\tacc: 0.91822\n",
      "[81], \tval loss: 0.014778\tacc: 0.57104\n",
      "[81], \ttrain loss: 0.0020527\tacc: 0.91906\n",
      "[82], \tval loss: 0.013752\tacc: 0.61749\n",
      "[82], \ttrain loss: 0.0021671\tacc: 0.90871\n",
      "[83], \tval loss: 0.015595\tacc: 0.5847\n",
      "[83], \ttrain loss: 0.0019845\tacc: 0.91989\n",
      "[84], \tval loss: 0.015403\tacc: 0.5888\n",
      "[84], \ttrain loss: 0.0021128\tacc: 0.91105\n",
      "[85], \tval loss: 0.012457\tacc: 0.61202\n",
      "[85], \ttrain loss: 0.0020708\tacc: 0.91288\n",
      "[86], \tval loss: 0.014971\tacc: 0.59016\n",
      "[86], \ttrain loss: 0.002044\tacc: 0.91872\n",
      "[87], \tval loss: 0.013856\tacc: 0.61612\n",
      "[87], \ttrain loss: 0.0020586\tacc: 0.91422\n",
      "[88], \tval loss: 0.014878\tacc: 0.59153\n",
      "[88], \ttrain loss: 0.0019293\tacc: 0.9229\n",
      "[89], \tval loss: 0.015103\tacc: 0.60383\n",
      "[89], \ttrain loss: 0.0018195\tacc: 0.9264\n",
      "[90], \tval loss: 0.013605\tacc: 0.59563\n",
      "[90], \ttrain loss: 0.0019802\tacc: 0.91772\n",
      "[91], \tval loss: 0.012364\tacc: 0.62432\n",
      "[91], \ttrain loss: 0.0020041\tacc: 0.92039\n",
      "[92], \tval loss: 0.014061\tacc: 0.61612\n",
      "[92], \ttrain loss: 0.0019929\tacc: 0.91656\n",
      "[93], \tval loss: 0.016887\tacc: 0.56421\n",
      "[93], \ttrain loss: 0.0019611\tacc: 0.92323\n",
      "[94], \tval loss: 0.013872\tacc: 0.60656\n",
      "[94], \ttrain loss: 0.0019905\tacc: 0.91956\n",
      "[95], \tval loss: 0.014596\tacc: 0.61339\n",
      "[95], \ttrain loss: 0.0019033\tacc: 0.92156\n",
      "[96], \tval loss: 0.014314\tacc: 0.59563\n",
      "[96], \ttrain loss: 0.0018845\tacc: 0.9274\n",
      "[97], \tval loss: 0.014945\tacc: 0.59153\n",
      "[97], \ttrain loss: 0.0018564\tacc: 0.92774\n",
      "[98], \tval loss: 0.012115\tacc: 0.60519\n",
      "[98], \ttrain loss: 0.0018748\tacc: 0.92573\n",
      "[99], \tval loss: 0.016025\tacc: 0.57104\n",
      "[99], \ttrain loss: 0.0019378\tacc: 0.92407\n",
      "[100], \tval loss: 0.013973\tacc: 0.59153\n",
      "[100], \ttrain loss: 0.0018301\tacc: 0.9269\n"
     ]
    }
   ],
   "source": [
    "from Utils.SiameseNet import SiameseNet, SiameseNet_large, MultiEncoding_SiameseNet, MultiEncoding_SiameseNet_Large\n",
    "import os\n",
    "\n",
    "name  = 'MultiEncoding_SiameseNet_large'\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = MultiEncoding_SiameseNet_Large().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(params= model.parameters(), lr = lr)\n",
    "\n",
    "num_epoch = 100\n",
    "best_epoch = 0\n",
    "best_val_acc = 0\n",
    "\n",
    "history = []\n",
    "accuracy = []\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    \n",
    "    train_loss, train_acc = train(model, trainloader, train_dataset, optimizer, device, criterion)\n",
    "    val_loss, val_acc  = validate(model, valloader, val_dataset, device, criterion)\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_epoch = epoch\n",
    "\n",
    "        save_path = os.getcwd() +'\\\\models\\\\{}_best.pt'.format(name)\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "\n",
    "\n",
    "    print('[{}], \\tval loss: {:.5}\\tacc: {:.5}'.format(epoch+1, val_loss, val_acc))\n",
    "    print('[{}], \\ttrain loss: {:.5}\\tacc: {:.5}'.format(epoch+1, train_loss, train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch : 4\n"
     ]
    }
   ],
   "source": [
    "print('best epoch : {}'.format(best_epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.getcwd() +'\\\\models\\\\{}_epoch{}.pt'.format(name, epoch+1)\n",
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
