{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset class for getting positive and negative classes for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a dictionary with (Family) \\\\\\\\ (ID) as the key and the path to the images under that one person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Utils.DatasetClass import SmileDataset\n",
    "import os\n",
    "import random\n",
    "\n",
    "train_file_path = \"./train_relationships.csv\"\n",
    "train_images_path = \"./data/baseline/train/\"\n",
    "\n",
    "all_images = glob(train_images_path + \"*/*/*.jpg\")\n",
    "\n",
    "\n",
    "train_person_to_images = {}\n",
    "val_person_to_images = {}\n",
    "\n",
    "# Getting 0.1 of the total training as validation\n",
    "percentage_val = 0.1\n",
    "train_names = [folder for folder in os.listdir(train_images_path) if  os.path.isdir(os.path.join(train_images_path, folder))]\n",
    "val_families = random.sample(train_names, int(percentage_val * len(train_names)))\n",
    "\n",
    "train_images = []\n",
    "val_images = []\n",
    "\n",
    "for x in all_images:\n",
    "\n",
    "    if x.split(\"\\\\\")[-3] not in val_families:\n",
    "\n",
    "        if x.split(\"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2] not in train_person_to_images:\n",
    "            train_person_to_images[x.split(\"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2]] = [x]\n",
    "\n",
    "        else:\n",
    "            train_person_to_images[x.split(\"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2]].append(x)\n",
    "\n",
    "        train_images.append(x)\n",
    "    \n",
    "    else:\n",
    "        if x.split(\"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2] not in val_person_to_images:\n",
    "            val_person_to_images[x.split(\"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2]] = [x]\n",
    "\n",
    "        else:\n",
    "            val_person_to_images[x.split(\"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2]].append(x)\n",
    "\n",
    "        val_images.append(x)\n",
    "\n",
    "train_people = [x.split(\"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2] for x in train_images]\n",
    "train_people = list(dict.fromkeys(train_people)) # removing the duplicates\n",
    "\n",
    "val_people = [x.split(\"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2] for x in val_images]\n",
    "val_people = list(dict.fromkeys(val_people)) # removing the duplicates\n",
    "\n",
    "relationships = pd.read_csv(train_file_path)\n",
    "relationships = list(zip(relationships.p1.values, relationships.p2.values))\n",
    "\n",
    "#relationships = [x for x in relationships for _ in range(2)] #Adding more data\n",
    "\n",
    "train_relationships = [x for x in relationships if x[0] in train_people and x[1] in train_people] #Check if people are in the training dataset\n",
    "val_relationships = [x for x in relationships if x[0] in val_people and x[1] in val_people]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3598"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, valloader, val_dataset, device, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    for batch in valloader:\n",
    "        tensor1, tensor2, label = batch\n",
    "        tensor1, tensor2, label = tensor1.to(device), tensor2.to(device), label.float().view(-1,1).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(tensor1, tensor2)\n",
    "            preds = output>0.5\n",
    "            loss = criterion(output, label)\n",
    "            \n",
    "        val_loss += loss.item()\n",
    "        running_corrects += torch.sum(preds == (label>0.5))\n",
    "    \n",
    "    val_loss /= len(val_dataset)\n",
    "    val_acc = running_corrects.item()/len(val_dataset)\n",
    "\n",
    "    return val_loss, val_acc\n",
    "\n",
    "def train(model, trainloader, train_dataset, optimizer, device, criterion, scheduler = None):\n",
    "    train_loss = 0.0\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for batch in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        tensor1, tensor2, label = batch\n",
    "        tensor1, tensor2, label = tensor1.to(device), tensor2.to(device), label.float().view(-1,1).to(device)\n",
    "        output = model(tensor1, tensor2)\n",
    "\n",
    "        preds = output>0.5\n",
    "        \n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        running_loss += loss.item()\n",
    "        running_corrects += torch.sum(preds == label)\n",
    "\n",
    "    train_loss /= len(train_dataset)\n",
    "    train_acc = running_corrects.item()/len(train_dataset)\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.SiameseNet import SiameseNet, SiameseNet_large, MultiEncoding_SiameseNet, MultiEncoding_SiameseNet_Large\n",
    "from Utils.SiameseNetLargeLarge import MultiEncoding_SiameseNet_LargeLarge\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import os\n",
    "from Utils.EarlyStopper import EarlyStopper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random sampling and creation of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Random Sample 1] :\n",
      "[1], \tval loss: 0.0055463\tacc: 0.69723\n",
      "[1], \ttrain loss: 0.0047436\tacc: 0.64806\n",
      "[2], \tval loss: 0.00521\tacc: 0.6955\n",
      "[2], \ttrain loss: 0.0044345\tacc: 0.68663\n",
      "[3], \tval loss: 0.0049496\tacc: 0.72318\n",
      "[3], \ttrain loss: 0.0042823\tacc: 0.69801\n",
      "[4], \tval loss: 0.0044767\tacc: 0.73875\n",
      "[4], \ttrain loss: 0.0042392\tacc: 0.71152\n",
      "[5], \tval loss: 0.0053653\tacc: 0.67993\n",
      "[5], \ttrain loss: 0.0041701\tacc: 0.72486\n",
      "[6], \tval loss: 0.0052733\tacc: 0.69031\n",
      "[6], \ttrain loss: 0.0043325\tacc: 0.69964\n",
      "[7], \tval loss: 0.0047519\tacc: 0.72837\n",
      "[7], \ttrain loss: 0.0041883\tacc: 0.71412\n",
      "[8], \tval loss: 0.0051396\tacc: 0.69723\n",
      "[8], \ttrain loss: 0.0040615\tacc: 0.72502\n",
      "[9], \tval loss: 0.0049819\tacc: 0.69377\n",
      "[9], \ttrain loss: 0.0040216\tacc: 0.74048\n",
      "Done! Early stopped at 9\n",
      "[Random Sample 2] :\n",
      "[1], \tval loss: 0.005678\tacc: 0.70934\n",
      "[1], \ttrain loss: 0.0046681\tacc: 0.67133\n",
      "[2], \tval loss: 0.0052992\tacc: 0.63841\n",
      "[2], \ttrain loss: 0.0045007\tacc: 0.68174\n",
      "[3], \tval loss: 0.0051261\tacc: 0.66263\n",
      "[3], \ttrain loss: 0.00432\tacc: 0.68842\n",
      "[4], \tval loss: 0.0051956\tacc: 0.67993\n",
      "[4], \ttrain loss: 0.004188\tacc: 0.71884\n",
      "[5], \tval loss: 0.0047257\tacc: 0.73875\n",
      "[5], \ttrain loss: 0.0040649\tacc: 0.72454\n",
      "[6], \tval loss: 0.0051299\tacc: 0.67993\n",
      "[6], \ttrain loss: 0.0040568\tacc: 0.72568\n",
      "[7], \tval loss: 0.0052012\tacc: 0.71626\n",
      "[7], \ttrain loss: 0.0040369\tacc: 0.72991\n",
      "[8], \tval loss: 0.0047181\tacc: 0.70242\n",
      "[8], \ttrain loss: 0.0039739\tacc: 0.73072\n",
      "[9], \tval loss: 0.0056725\tacc: 0.6609\n",
      "[9], \ttrain loss: 0.0038472\tacc: 0.7439\n",
      "[10], \tval loss: 0.0050688\tacc: 0.6609\n",
      "[10], \ttrain loss: 0.0040447\tacc: 0.74195\n",
      "[11], \tval loss: 0.004717\tacc: 0.70588\n",
      "[11], \ttrain loss: 0.003902\tacc: 0.73723\n",
      "[12], \tval loss: 0.004951\tacc: 0.71453\n",
      "[12], \ttrain loss: 0.0038553\tacc: 0.75773\n",
      "[13], \tval loss: 0.0047156\tacc: 0.73183\n",
      "[13], \ttrain loss: 0.0037302\tacc: 0.76001\n",
      "[14], \tval loss: 0.0057156\tacc: 0.61938\n",
      "[14], \ttrain loss: 0.0040087\tacc: 0.75561\n",
      "[15], \tval loss: 0.0048353\tacc: 0.7301\n",
      "[15], \ttrain loss: 0.0038063\tacc: 0.75138\n",
      "[16], \tval loss: 0.0052119\tacc: 0.70761\n",
      "[16], \ttrain loss: 0.0037457\tacc: 0.7465\n",
      "[17], \tval loss: 0.0049262\tacc: 0.7128\n",
      "[17], \ttrain loss: 0.0035791\tacc: 0.767\n",
      "[18], \tval loss: 0.0050475\tacc: 0.70588\n",
      "[18], \ttrain loss: 0.0034703\tacc: 0.77856\n",
      "Done! Early stopped at 18\n",
      "[Random Sample 3] :\n",
      "[1], \tval loss: 0.0053031\tacc: 0.66609\n",
      "[1], \ttrain loss: 0.0046816\tacc: 0.66075\n",
      "[2], \tval loss: 0.0056112\tacc: 0.68858\n",
      "[2], \ttrain loss: 0.0043739\tacc: 0.69378\n",
      "[3], \tval loss: 0.0050287\tacc: 0.70069\n",
      "[3], \ttrain loss: 0.0044463\tacc: 0.68386\n",
      "[4], \tval loss: 0.0052819\tacc: 0.6955\n",
      "[4], \ttrain loss: 0.0042325\tacc: 0.71266\n",
      "[5], \tval loss: 0.0051963\tacc: 0.68512\n",
      "[5], \ttrain loss: 0.0041769\tacc: 0.72014\n",
      "[6], \tval loss: 0.00499\tacc: 0.67301\n",
      "[6], \ttrain loss: 0.0043043\tacc: 0.7138\n",
      "[7], \tval loss: 0.0050133\tacc: 0.67128\n",
      "[7], \ttrain loss: 0.0041065\tacc: 0.7138\n",
      "[8], \tval loss: 0.0049388\tacc: 0.65744\n",
      "[8], \ttrain loss: 0.0038877\tacc: 0.73755\n",
      "[9], \tval loss: 0.0048326\tacc: 0.70588\n",
      "[9], \ttrain loss: 0.0038826\tacc: 0.73885\n",
      "[10], \tval loss: 0.0046401\tacc: 0.74394\n",
      "[10], \ttrain loss: 0.0039657\tacc: 0.74374\n",
      "[11], \tval loss: 0.0060383\tacc: 0.64014\n",
      "[11], \ttrain loss: 0.0037891\tacc: 0.74227\n",
      "[12], \tval loss: 0.0049871\tacc: 0.73183\n",
      "[12], \ttrain loss: 0.0039792\tacc: 0.74048\n",
      "[13], \tval loss: 0.0052226\tacc: 0.70069\n",
      "[13], \ttrain loss: 0.003812\tacc: 0.75041\n",
      "[14], \tval loss: 0.0046369\tacc: 0.71799\n",
      "[14], \ttrain loss: 0.0036489\tacc: 0.76456\n",
      "[15], \tval loss: 0.0057206\tacc: 0.64879\n",
      "[15], \ttrain loss: 0.0035979\tacc: 0.76375\n",
      "[16], \tval loss: 0.0053237\tacc: 0.69896\n",
      "[16], \ttrain loss: 0.0036611\tacc: 0.76131\n",
      "[17], \tval loss: 0.004615\tacc: 0.71107\n",
      "[17], \ttrain loss: 0.0035623\tacc: 0.7657\n",
      "[18], \tval loss: 0.0048796\tacc: 0.69031\n",
      "[18], \ttrain loss: 0.0034547\tacc: 0.77644\n",
      "[19], \tval loss: 0.0050078\tacc: 0.70069\n",
      "[19], \ttrain loss: 0.0033831\tacc: 0.781\n",
      "[20], \tval loss: 0.0053254\tacc: 0.67993\n",
      "[20], \ttrain loss: 0.0035518\tacc: 0.78571\n",
      "[21], \tval loss: 0.0051083\tacc: 0.70415\n",
      "[21], \ttrain loss: 0.0034367\tacc: 0.77693\n",
      "[22], \tval loss: 0.0048683\tacc: 0.71107\n",
      "[22], \ttrain loss: 0.0033835\tacc: 0.79792\n",
      "Done! Early stopped at 22\n",
      "[Random Sample 4] :\n",
      "[1], \tval loss: 0.0056274\tacc: 0.69377\n",
      "[1], \ttrain loss: 0.0046789\tacc: 0.65327\n",
      "[2], \tval loss: 0.004898\tacc: 0.70242\n",
      "[2], \ttrain loss: 0.0044953\tacc: 0.67345\n",
      "[3], \tval loss: 0.0055643\tacc: 0.64879\n",
      "[3], \ttrain loss: 0.0042999\tacc: 0.70582\n",
      "[4], \tval loss: 0.004817\tacc: 0.69031\n",
      "[4], \ttrain loss: 0.0041808\tacc: 0.70924\n",
      "[5], \tval loss: 0.0045688\tacc: 0.71107\n",
      "[5], \ttrain loss: 0.004098\tacc: 0.71933\n",
      "[6], \tval loss: 0.00494\tacc: 0.70761\n",
      "[6], \ttrain loss: 0.0039945\tacc: 0.72909\n",
      "[7], \tval loss: 0.0049354\tacc: 0.68512\n",
      "[7], \ttrain loss: 0.0039391\tacc: 0.74748\n",
      "[8], \tval loss: 0.0046547\tacc: 0.71799\n",
      "[8], \ttrain loss: 0.0040025\tacc: 0.72714\n",
      "[9], \tval loss: 0.005044\tacc: 0.66263\n",
      "[9], \ttrain loss: 0.0040388\tacc: 0.74406\n",
      "[10], \tval loss: 0.0049901\tacc: 0.67993\n",
      "[10], \ttrain loss: 0.0039016\tacc: 0.73153\n",
      "Done! Early stopped at 10\n",
      "[Random Sample 5] :\n",
      "[1], \tval loss: 0.0053698\tacc: 0.57785\n",
      "[1], \ttrain loss: 0.0046727\tacc: 0.65099\n",
      "[2], \tval loss: 0.0049798\tacc: 0.71799\n",
      "[2], \ttrain loss: 0.0043804\tacc: 0.68126\n",
      "[3], \tval loss: 0.0049028\tacc: 0.7128\n",
      "[3], \ttrain loss: 0.0042393\tacc: 0.71282\n",
      "[4], \tval loss: 0.0050087\tacc: 0.71972\n",
      "[4], \ttrain loss: 0.0042551\tacc: 0.70973\n",
      "[5], \tval loss: 0.0050519\tacc: 0.71107\n",
      "[5], \ttrain loss: 0.0043581\tacc: 0.70713\n",
      "[6], \tval loss: 0.0051474\tacc: 0.71626\n",
      "[6], \ttrain loss: 0.0041648\tacc: 0.7094\n",
      "[7], \tval loss: 0.0048346\tacc: 0.72837\n",
      "[7], \ttrain loss: 0.0042066\tacc: 0.72063\n",
      "[8], \tval loss: 0.0054453\tacc: 0.64706\n",
      "[8], \ttrain loss: 0.004298\tacc: 0.71022\n",
      "[9], \tval loss: 0.0050852\tacc: 0.6609\n",
      "[9], \ttrain loss: 0.0041689\tacc: 0.70713\n",
      "[10], \tval loss: 0.0052085\tacc: 0.67128\n",
      "[10], \ttrain loss: 0.0039263\tacc: 0.72486\n",
      "[11], \tval loss: 0.0052022\tacc: 0.70069\n",
      "[11], \ttrain loss: 0.0038527\tacc: 0.74308\n",
      "[12], \tval loss: 0.0049996\tacc: 0.70934\n",
      "[12], \ttrain loss: 0.0039104\tacc: 0.7478\n",
      "Done! Early stopped at 12\n",
      "[Random Sample 6] :\n",
      "[1], \tval loss: 0.0055367\tacc: 0.67993\n",
      "[1], \ttrain loss: 0.0047001\tacc: 0.66059\n",
      "[2], \tval loss: 0.0050834\tacc: 0.66436\n",
      "[2], \ttrain loss: 0.0044589\tacc: 0.68093\n",
      "[3], \tval loss: 0.0054225\tacc: 0.60208\n",
      "[3], \ttrain loss: 0.0042549\tacc: 0.70582\n",
      "[4], \tval loss: 0.0050018\tacc: 0.66263\n",
      "[4], \ttrain loss: 0.0042522\tacc: 0.70957\n",
      "[5], \tval loss: 0.0050744\tacc: 0.6955\n",
      "[5], \ttrain loss: 0.0041013\tacc: 0.71754\n",
      "[6], \tval loss: 0.0047352\tacc: 0.70588\n",
      "[6], \ttrain loss: 0.0042291\tacc: 0.71689\n",
      "[7], \tval loss: 0.0047928\tacc: 0.74567\n",
      "[7], \ttrain loss: 0.0040623\tacc: 0.72405\n",
      "[8], \tval loss: 0.0050191\tacc: 0.69377\n",
      "[8], \ttrain loss: 0.0041456\tacc: 0.71477\n",
      "[9], \tval loss: 0.0052065\tacc: 0.65917\n",
      "[9], \ttrain loss: 0.0041041\tacc: 0.74569\n",
      "[10], \tval loss: 0.0048769\tacc: 0.68858\n",
      "[10], \ttrain loss: 0.0039146\tacc: 0.73137\n",
      "[11], \tval loss: 0.0051933\tacc: 0.67993\n",
      "[11], \ttrain loss: 0.0038334\tacc: 0.74732\n",
      "Done! Early stopped at 11\n",
      "[Random Sample 7] :\n",
      "[1], \tval loss: 0.005426\tacc: 0.6609\n",
      "[1], \ttrain loss: 0.0046103\tacc: 0.65636\n",
      "[2], \tval loss: 0.0052911\tacc: 0.70069\n",
      "[2], \ttrain loss: 0.0043171\tacc: 0.68353\n",
      "[3], \tval loss: 0.0048736\tacc: 0.71626\n",
      "[3], \ttrain loss: 0.0042894\tacc: 0.70192\n",
      "[4], \tval loss: 0.0045911\tacc: 0.73529\n",
      "[4], \ttrain loss: 0.0041924\tacc: 0.71542\n",
      "[5], \tval loss: 0.0050057\tacc: 0.70242\n",
      "[5], \ttrain loss: 0.0039923\tacc: 0.73495\n",
      "[6], \tval loss: 0.0048995\tacc: 0.69377\n",
      "[6], \ttrain loss: 0.0040513\tacc: 0.73104\n",
      "[7], \tval loss: 0.0053054\tacc: 0.70069\n",
      "[7], \ttrain loss: 0.0039551\tacc: 0.72909\n",
      "[8], \tval loss: 0.0049233\tacc: 0.72145\n",
      "[8], \ttrain loss: 0.0039736\tacc: 0.73153\n",
      "[9], \tval loss: 0.0050226\tacc: 0.69723\n",
      "[9], \ttrain loss: 0.0038087\tacc: 0.74504\n",
      "Done! Early stopped at 9\n",
      "[Random Sample 8] :\n",
      "[1], \tval loss: 0.0055102\tacc: 0.60554\n",
      "[1], \ttrain loss: 0.0047075\tacc: 0.65604\n",
      "[2], \tval loss: 0.005687\tacc: 0.58478\n",
      "[2], \ttrain loss: 0.0044284\tacc: 0.67328\n",
      "[3], \tval loss: 0.0047708\tacc: 0.7301\n",
      "[3], \ttrain loss: 0.0042051\tacc: 0.70761\n",
      "[4], \tval loss: 0.0048196\tacc: 0.71799\n",
      "[4], \ttrain loss: 0.0041173\tacc: 0.72568\n",
      "[5], \tval loss: 0.0051097\tacc: 0.69031\n",
      "[5], \ttrain loss: 0.0040933\tacc: 0.72128\n",
      "[6], \tval loss: 0.0050477\tacc: 0.70761\n",
      "[6], \ttrain loss: 0.0041989\tacc: 0.73397\n",
      "[7], \tval loss: 0.0049434\tacc: 0.69377\n",
      "[7], \ttrain loss: 0.0041174\tacc: 0.72714\n",
      "[8], \tval loss: 0.0050722\tacc: 0.71972\n",
      "[8], \ttrain loss: 0.0039126\tacc: 0.7356\n",
      "Done! Early stopped at 8\n",
      "[Random Sample 9] :\n",
      "[1], \tval loss: 0.0055341\tacc: 0.70242\n",
      "[1], \ttrain loss: 0.004659\tacc: 0.65766\n",
      "[2], \tval loss: 0.0048656\tacc: 0.70588\n",
      "[2], \ttrain loss: 0.0043678\tacc: 0.68955\n",
      "[3], \tval loss: 0.0050627\tacc: 0.67301\n",
      "[3], \ttrain loss: 0.0041362\tacc: 0.72177\n",
      "[4], \tval loss: 0.0048201\tacc: 0.67647\n",
      "[4], \ttrain loss: 0.0042179\tacc: 0.71168\n",
      "[5], \tval loss: 0.0046681\tacc: 0.71453\n",
      "[5], \ttrain loss: 0.004073\tacc: 0.71477\n",
      "[6], \tval loss: 0.0048412\tacc: 0.69896\n",
      "[6], \ttrain loss: 0.0039707\tacc: 0.73625\n",
      "[7], \tval loss: 0.004907\tacc: 0.70069\n",
      "[7], \ttrain loss: 0.0040186\tacc: 0.73853\n",
      "[8], \tval loss: 0.0052896\tacc: 0.70588\n",
      "[8], \ttrain loss: 0.0039\tacc: 0.73511\n",
      "[9], \tval loss: 0.0053983\tacc: 0.65917\n",
      "[9], \ttrain loss: 0.0036948\tacc: 0.75268\n",
      "[10], \tval loss: 0.0054708\tacc: 0.65052\n",
      "[10], \ttrain loss: 0.0037177\tacc: 0.75447\n",
      "Done! Early stopped at 10\n",
      "[Random Sample 10] :\n",
      "[1], \tval loss: 0.0053254\tacc: 0.64014\n",
      "[1], \ttrain loss: 0.0046255\tacc: 0.65783\n",
      "[2], \tval loss: 0.0046786\tacc: 0.73529\n",
      "[2], \ttrain loss: 0.0044009\tacc: 0.68272\n",
      "[3], \tval loss: 0.0051482\tacc: 0.66263\n",
      "[3], \ttrain loss: 0.0042125\tacc: 0.71445\n",
      "[4], \tval loss: 0.0049114\tacc: 0.71453\n",
      "[4], \ttrain loss: 0.0042567\tacc: 0.69818\n",
      "[5], \tval loss: 0.0054965\tacc: 0.62284\n",
      "[5], \ttrain loss: 0.0040932\tacc: 0.72616\n",
      "[6], \tval loss: 0.0052892\tacc: 0.69723\n",
      "[6], \ttrain loss: 0.0040795\tacc: 0.71884\n",
      "[7], \tval loss: 0.0049939\tacc: 0.67993\n",
      "[7], \ttrain loss: 0.0039118\tacc: 0.73658\n",
      "Done! Early stopped at 7\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "n = 10\n",
    "sample_percentage = 0.7\n",
    "length_of_train = len(train_relationships)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "val_dataset = SmileDataset(relations = val_relationships, person_to_image= val_person_to_images, rgb = True)\n",
    "valloader = DataLoader(val_dataset, batch_size= batch_size, shuffle = True)\n",
    "\n",
    "num_epoch = 50\n",
    "patience = 5\n",
    "\n",
    "accuracy = []\n",
    "\n",
    "name  = 'MultiEncoding_SiameseNet_Large_Random_Sample'\n",
    "\n",
    "for m in range(n):\n",
    "\n",
    "    print('[Random Sample {}] :'.format(m+1))\n",
    "\n",
    "    # Get random sample of rtrain data\n",
    "    random_sample = random.sample(train_relationships, round(sample_percentage * length_of_train))\n",
    "    train_dataset = SmileDataset(relations = train_relationships, person_to_image= train_person_to_images, rgb= True)\n",
    "    trainloader = DataLoader(train_dataset, batch_size= batch_size, shuffle = True)\n",
    "\n",
    "    best_val_acc = 0\n",
    "    best_epoch = 0\n",
    "\n",
    "    # Instantiate the model and related stuff\n",
    "    lr = 0.001\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = MultiEncoding_SiameseNet_Large().to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(params= model.parameters(), lr = lr)\n",
    "    early_stopper = EarlyStopper(patience=patience, min_delta=0)\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        \n",
    "        train_loss, train_acc = train(model, trainloader, train_dataset, optimizer, device, criterion)\n",
    "        val_loss, val_acc  = validate(model, valloader, val_dataset, device, criterion)\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_epoch = epoch\n",
    "\n",
    "            save_path = os.getcwd() +'\\\\models\\\\random_sample\\\\{}_best_bagging{}.pt'.format(name, m+1)\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "\n",
    "\n",
    "        print('[{}], \\tval loss: {:.5}\\tacc: {:.5}'.format(epoch+1, val_loss, val_acc))\n",
    "        print('[{}], \\ttrain loss: {:.5}\\tacc: {:.5}'.format(epoch+1, train_loss, train_acc))\n",
    "\n",
    "        if early_stopper.early_stop(val_loss):\n",
    "            print(\"Done! Early stopped at {}\".format(epoch+1))\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training time!! :) (Work in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.getcwd() +'\\\\models\\\\{}_epoch{}.pt'.format(name, epoch+1)\n",
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
